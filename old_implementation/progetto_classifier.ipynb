{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ca73d63-1bd2-4a4a-bd70-f9bedd5db0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:17: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\Marco\\AppData\\Local\\Temp\\ipykernel_13976\\1750349307.py:17: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  data = pd.read_csv('D:\\progetto_video\\dataset\\dataset_tutto2.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marco\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3010 - loss: 1.7149 - val_accuracy: 0.7153 - val_loss: 0.8334\n",
      "Epoch 2/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6552 - loss: 0.8865 - val_accuracy: 0.8158 - val_loss: 0.5662\n",
      "Epoch 3/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7584 - loss: 0.6505 - val_accuracy: 0.8763 - val_loss: 0.4053\n",
      "Epoch 4/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8185 - loss: 0.5075 - val_accuracy: 0.9011 - val_loss: 0.3305\n",
      "Epoch 5/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8452 - loss: 0.4511 - val_accuracy: 0.9329 - val_loss: 0.2548\n",
      "Epoch 6/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8712 - loss: 0.3739 - val_accuracy: 0.9224 - val_loss: 0.2473\n",
      "Epoch 7/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8832 - loss: 0.3515 - val_accuracy: 0.9411 - val_loss: 0.2122\n",
      "Epoch 8/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8899 - loss: 0.3225 - val_accuracy: 0.9429 - val_loss: 0.2005\n",
      "Epoch 9/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9018 - loss: 0.3097 - val_accuracy: 0.9439 - val_loss: 0.1976\n",
      "Epoch 10/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9019 - loss: 0.3011 - val_accuracy: 0.9434 - val_loss: 0.1782\n",
      "Epoch 11/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9060 - loss: 0.2902 - val_accuracy: 0.9455 - val_loss: 0.1728\n",
      "Epoch 12/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9117 - loss: 0.2759 - val_accuracy: 0.9424 - val_loss: 0.1902\n",
      "Epoch 13/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9097 - loss: 0.2693 - val_accuracy: 0.9513 - val_loss: 0.1607\n",
      "Epoch 14/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9128 - loss: 0.2619 - val_accuracy: 0.9429 - val_loss: 0.1658\n",
      "Epoch 15/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9197 - loss: 0.2462 - val_accuracy: 0.9542 - val_loss: 0.1542\n",
      "Epoch 16/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.2579 - val_accuracy: 0.9521 - val_loss: 0.1487\n",
      "Epoch 17/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9174 - loss: 0.2427 - val_accuracy: 0.9550 - val_loss: 0.1418\n",
      "Epoch 18/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9229 - loss: 0.2314 - val_accuracy: 0.9463 - val_loss: 0.1557\n",
      "Epoch 19/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9196 - loss: 0.2315 - val_accuracy: 0.9508 - val_loss: 0.1369\n",
      "Epoch 20/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9201 - loss: 0.2407 - val_accuracy: 0.9539 - val_loss: 0.1388\n",
      "Epoch 21/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9232 - loss: 0.2290 - val_accuracy: 0.9542 - val_loss: 0.1384\n",
      "Epoch 22/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.2111 - val_accuracy: 0.9555 - val_loss: 0.1386\n",
      "Epoch 23/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.2301 - val_accuracy: 0.9597 - val_loss: 0.1310\n",
      "Epoch 24/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9293 - loss: 0.2117 - val_accuracy: 0.9582 - val_loss: 0.1287\n",
      "Epoch 25/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9294 - loss: 0.2160 - val_accuracy: 0.9589 - val_loss: 0.1286\n",
      "Epoch 26/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9297 - loss: 0.2030 - val_accuracy: 0.9621 - val_loss: 0.1294\n",
      "Epoch 27/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9304 - loss: 0.2149 - val_accuracy: 0.9600 - val_loss: 0.1280\n",
      "Epoch 28/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9326 - loss: 0.1991 - val_accuracy: 0.9555 - val_loss: 0.1253\n",
      "Epoch 29/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9311 - loss: 0.2074 - val_accuracy: 0.9621 - val_loss: 0.1172\n",
      "Epoch 30/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9367 - loss: 0.1885 - val_accuracy: 0.9616 - val_loss: 0.1209\n",
      "Epoch 31/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9314 - loss: 0.2036 - val_accuracy: 0.9611 - val_loss: 0.1207\n",
      "Epoch 32/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9329 - loss: 0.1942 - val_accuracy: 0.9608 - val_loss: 0.1216\n",
      "Epoch 33/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9374 - loss: 0.1943 - val_accuracy: 0.9589 - val_loss: 0.1216\n",
      "Epoch 34/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9368 - loss: 0.1956 - val_accuracy: 0.9647 - val_loss: 0.1058\n",
      "Epoch 35/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9359 - loss: 0.1908 - val_accuracy: 0.9629 - val_loss: 0.1145\n",
      "Epoch 36/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9365 - loss: 0.1872 - val_accuracy: 0.9568 - val_loss: 0.1179\n",
      "Epoch 37/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9372 - loss: 0.1870 - val_accuracy: 0.9618 - val_loss: 0.1207\n",
      "Epoch 38/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9413 - loss: 0.1817 - val_accuracy: 0.9600 - val_loss: 0.1229\n",
      "Epoch 39/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9432 - loss: 0.1784 - val_accuracy: 0.9629 - val_loss: 0.1164\n",
      "Epoch 40/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9424 - loss: 0.1767 - val_accuracy: 0.9679 - val_loss: 0.1089\n",
      "Epoch 41/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9390 - loss: 0.1851 - val_accuracy: 0.9566 - val_loss: 0.1260\n",
      "Epoch 42/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9412 - loss: 0.1817 - val_accuracy: 0.9671 - val_loss: 0.1081\n",
      "Epoch 43/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9368 - loss: 0.1831 - val_accuracy: 0.9663 - val_loss: 0.1064\n",
      "Epoch 44/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9400 - loss: 0.1762 - val_accuracy: 0.9637 - val_loss: 0.1096\n",
      "Epoch 45/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9420 - loss: 0.1704 - val_accuracy: 0.9674 - val_loss: 0.0986\n",
      "Epoch 46/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9436 - loss: 0.1686 - val_accuracy: 0.9674 - val_loss: 0.0997\n",
      "Epoch 47/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9378 - loss: 0.1902 - val_accuracy: 0.9650 - val_loss: 0.1033\n",
      "Epoch 48/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9429 - loss: 0.1627 - val_accuracy: 0.9666 - val_loss: 0.1045\n",
      "Epoch 49/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9415 - loss: 0.1722 - val_accuracy: 0.9687 - val_loss: 0.0972\n",
      "Epoch 50/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9394 - loss: 0.1749 - val_accuracy: 0.9682 - val_loss: 0.1014\n",
      "Epoch 51/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9452 - loss: 0.1638 - val_accuracy: 0.9634 - val_loss: 0.1022\n",
      "Epoch 52/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9446 - loss: 0.1649 - val_accuracy: 0.9647 - val_loss: 0.1063\n",
      "Epoch 53/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9404 - loss: 0.1856 - val_accuracy: 0.9724 - val_loss: 0.0958\n",
      "Epoch 54/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9417 - loss: 0.1719 - val_accuracy: 0.9682 - val_loss: 0.0967\n",
      "Epoch 55/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9474 - loss: 0.1635 - val_accuracy: 0.9711 - val_loss: 0.0928\n",
      "Epoch 56/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.1642 - val_accuracy: 0.9682 - val_loss: 0.0985\n",
      "Epoch 57/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9392 - loss: 0.1697 - val_accuracy: 0.9663 - val_loss: 0.0968\n",
      "Epoch 58/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9439 - loss: 0.1644 - val_accuracy: 0.9684 - val_loss: 0.0950\n",
      "Epoch 59/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9488 - loss: 0.1582 - val_accuracy: 0.9613 - val_loss: 0.1113\n",
      "Epoch 60/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9410 - loss: 0.1749 - val_accuracy: 0.9689 - val_loss: 0.0985\n",
      "Epoch 61/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.1581 - val_accuracy: 0.9697 - val_loss: 0.0976\n",
      "Epoch 62/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9493 - loss: 0.1471 - val_accuracy: 0.9711 - val_loss: 0.0949\n",
      "Epoch 63/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9438 - loss: 0.1654 - val_accuracy: 0.9676 - val_loss: 0.0991\n",
      "Epoch 64/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9440 - loss: 0.1678 - val_accuracy: 0.9663 - val_loss: 0.0997\n",
      "Epoch 65/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9441 - loss: 0.1585 - val_accuracy: 0.9695 - val_loss: 0.0905\n",
      "Epoch 66/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9483 - loss: 0.1471 - val_accuracy: 0.9708 - val_loss: 0.0929\n",
      "Epoch 67/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9452 - loss: 0.1590 - val_accuracy: 0.9645 - val_loss: 0.1004\n",
      "Epoch 68/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.1498 - val_accuracy: 0.9703 - val_loss: 0.0940\n",
      "Epoch 69/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.1619 - val_accuracy: 0.9695 - val_loss: 0.1010\n",
      "Epoch 70/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9457 - loss: 0.1548 - val_accuracy: 0.9689 - val_loss: 0.0926\n",
      "Epoch 71/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.1540 - val_accuracy: 0.9689 - val_loss: 0.0959\n",
      "Epoch 72/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9464 - loss: 0.1622 - val_accuracy: 0.9697 - val_loss: 0.0851\n",
      "Epoch 73/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9454 - loss: 0.1587 - val_accuracy: 0.9674 - val_loss: 0.0911\n",
      "Epoch 74/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9514 - loss: 0.1454 - val_accuracy: 0.9687 - val_loss: 0.1047\n",
      "Epoch 75/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9450 - loss: 0.1548 - val_accuracy: 0.9737 - val_loss: 0.0857\n",
      "Epoch 76/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9531 - loss: 0.1386 - val_accuracy: 0.9647 - val_loss: 0.0980\n",
      "Epoch 77/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.1507 - val_accuracy: 0.9703 - val_loss: 0.0939\n",
      "Epoch 78/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9494 - loss: 0.1454 - val_accuracy: 0.9708 - val_loss: 0.0867\n",
      "Epoch 79/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9512 - loss: 0.1495 - val_accuracy: 0.9732 - val_loss: 0.0856\n",
      "Epoch 80/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9507 - loss: 0.1472 - val_accuracy: 0.9739 - val_loss: 0.0827\n",
      "Epoch 81/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.1460 - val_accuracy: 0.9739 - val_loss: 0.0839\n",
      "Epoch 82/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9497 - loss: 0.1495 - val_accuracy: 0.9713 - val_loss: 0.0895\n",
      "Epoch 83/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9515 - loss: 0.1409 - val_accuracy: 0.9711 - val_loss: 0.0870\n",
      "Epoch 84/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9470 - loss: 0.1556 - val_accuracy: 0.9732 - val_loss: 0.0847\n",
      "Epoch 85/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.1387 - val_accuracy: 0.9737 - val_loss: 0.0910\n",
      "Epoch 86/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9487 - loss: 0.1459 - val_accuracy: 0.9753 - val_loss: 0.0870\n",
      "Epoch 87/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9480 - loss: 0.1491 - val_accuracy: 0.9729 - val_loss: 0.0935\n",
      "Epoch 88/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9501 - loss: 0.1503 - val_accuracy: 0.9692 - val_loss: 0.0864\n",
      "Epoch 89/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9470 - loss: 0.1561 - val_accuracy: 0.9703 - val_loss: 0.0876\n",
      "Epoch 90/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9546 - loss: 0.1423 - val_accuracy: 0.9692 - val_loss: 0.0973\n",
      "Epoch 91/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9489 - loss: 0.1490 - val_accuracy: 0.9708 - val_loss: 0.0883\n",
      "Epoch 92/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9541 - loss: 0.1380 - val_accuracy: 0.9734 - val_loss: 0.0821\n",
      "Epoch 93/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9516 - loss: 0.1400 - val_accuracy: 0.9737 - val_loss: 0.0836\n",
      "Epoch 94/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9501 - loss: 0.1423 - val_accuracy: 0.9734 - val_loss: 0.0837\n",
      "Epoch 95/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9548 - loss: 0.1372 - val_accuracy: 0.9771 - val_loss: 0.0798\n",
      "Epoch 96/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9510 - loss: 0.1570 - val_accuracy: 0.9705 - val_loss: 0.0880\n",
      "Epoch 97/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.1499 - val_accuracy: 0.9750 - val_loss: 0.0826\n",
      "Epoch 98/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9547 - loss: 0.1319 - val_accuracy: 0.9650 - val_loss: 0.0990\n",
      "Epoch 99/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9452 - loss: 0.1563 - val_accuracy: 0.9700 - val_loss: 0.0884\n",
      "Epoch 100/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9492 - loss: 0.1466 - val_accuracy: 0.9732 - val_loss: 0.0785\n",
      "Epoch 101/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9526 - loss: 0.1333 - val_accuracy: 0.9716 - val_loss: 0.0909\n",
      "Epoch 102/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9544 - loss: 0.1344 - val_accuracy: 0.9755 - val_loss: 0.0843\n",
      "Epoch 103/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9508 - loss: 0.1424 - val_accuracy: 0.9750 - val_loss: 0.0855\n",
      "Epoch 104/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9529 - loss: 0.1510 - val_accuracy: 0.9732 - val_loss: 0.0827\n",
      "Epoch 105/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9512 - loss: 0.1375 - val_accuracy: 0.9758 - val_loss: 0.0785\n",
      "Epoch 106/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9577 - loss: 0.1202 - val_accuracy: 0.9758 - val_loss: 0.0805\n",
      "Epoch 107/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9534 - loss: 0.1346 - val_accuracy: 0.9692 - val_loss: 0.0936\n",
      "Epoch 108/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9513 - loss: 0.1473 - val_accuracy: 0.9737 - val_loss: 0.0882\n",
      "Epoch 109/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9514 - loss: 0.1402 - val_accuracy: 0.9700 - val_loss: 0.0861\n",
      "Epoch 110/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9482 - loss: 0.1523 - val_accuracy: 0.9682 - val_loss: 0.0928\n",
      "Epoch 111/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.1466 - val_accuracy: 0.9758 - val_loss: 0.0775\n",
      "Epoch 112/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9550 - loss: 0.1288 - val_accuracy: 0.9755 - val_loss: 0.0792\n",
      "Epoch 113/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9512 - loss: 0.1399 - val_accuracy: 0.9739 - val_loss: 0.0827\n",
      "Epoch 114/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9559 - loss: 0.1285 - val_accuracy: 0.9692 - val_loss: 0.0870\n",
      "Epoch 115/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9576 - loss: 0.1276 - val_accuracy: 0.9753 - val_loss: 0.0767\n",
      "Epoch 116/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9541 - loss: 0.1250 - val_accuracy: 0.9761 - val_loss: 0.0780\n",
      "Epoch 117/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9557 - loss: 0.1306 - val_accuracy: 0.9763 - val_loss: 0.0787\n",
      "Epoch 118/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9563 - loss: 0.1270 - val_accuracy: 0.9684 - val_loss: 0.0936\n",
      "Epoch 119/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9540 - loss: 0.1341 - val_accuracy: 0.9758 - val_loss: 0.0770\n",
      "Epoch 120/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9563 - loss: 0.1287 - val_accuracy: 0.9724 - val_loss: 0.0801\n",
      "Epoch 121/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9542 - loss: 0.1349 - val_accuracy: 0.9745 - val_loss: 0.0791\n",
      "Epoch 122/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9558 - loss: 0.1305 - val_accuracy: 0.9742 - val_loss: 0.0815\n",
      "Epoch 123/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9554 - loss: 0.1262 - val_accuracy: 0.9708 - val_loss: 0.0843\n",
      "Epoch 124/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9531 - loss: 0.1343 - val_accuracy: 0.9747 - val_loss: 0.0776\n",
      "Epoch 125/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9522 - loss: 0.1408 - val_accuracy: 0.9755 - val_loss: 0.0756\n",
      "Epoch 126/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9569 - loss: 0.1283 - val_accuracy: 0.9758 - val_loss: 0.0754\n",
      "Epoch 127/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9552 - loss: 0.1320 - val_accuracy: 0.9718 - val_loss: 0.0767\n",
      "Epoch 128/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9559 - loss: 0.1300 - val_accuracy: 0.9737 - val_loss: 0.0831\n",
      "Epoch 129/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9542 - loss: 0.1296 - val_accuracy: 0.9745 - val_loss: 0.0803\n",
      "Epoch 130/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9588 - loss: 0.1216 - val_accuracy: 0.9776 - val_loss: 0.0739\n",
      "Epoch 131/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9602 - loss: 0.1168 - val_accuracy: 0.9758 - val_loss: 0.0738\n",
      "Epoch 132/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9557 - loss: 0.1286 - val_accuracy: 0.9761 - val_loss: 0.0748\n",
      "Epoch 133/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9520 - loss: 0.1378 - val_accuracy: 0.9753 - val_loss: 0.0741\n",
      "Epoch 134/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9593 - loss: 0.1138 - val_accuracy: 0.9753 - val_loss: 0.0755\n",
      "Epoch 135/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9577 - loss: 0.1264 - val_accuracy: 0.9724 - val_loss: 0.0829\n",
      "Epoch 136/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9557 - loss: 0.1284 - val_accuracy: 0.9768 - val_loss: 0.0757\n",
      "Epoch 137/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9555 - loss: 0.1289 - val_accuracy: 0.9782 - val_loss: 0.0725\n",
      "Epoch 138/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9552 - loss: 0.1347 - val_accuracy: 0.9745 - val_loss: 0.0803\n",
      "Epoch 139/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9570 - loss: 0.1328 - val_accuracy: 0.9763 - val_loss: 0.0767\n",
      "Epoch 140/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9583 - loss: 0.1256 - val_accuracy: 0.9750 - val_loss: 0.0792\n",
      "Epoch 141/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9580 - loss: 0.1251 - val_accuracy: 0.9726 - val_loss: 0.0802\n",
      "Epoch 142/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9589 - loss: 0.1234 - val_accuracy: 0.9774 - val_loss: 0.0735\n",
      "Epoch 143/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9620 - loss: 0.1162 - val_accuracy: 0.9750 - val_loss: 0.0857\n",
      "Epoch 144/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9539 - loss: 0.1365 - val_accuracy: 0.9742 - val_loss: 0.0786\n",
      "Epoch 145/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9605 - loss: 0.1248 - val_accuracy: 0.9768 - val_loss: 0.0763\n",
      "Epoch 146/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9571 - loss: 0.1210 - val_accuracy: 0.9782 - val_loss: 0.0757\n",
      "Epoch 147/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9593 - loss: 0.1168 - val_accuracy: 0.9776 - val_loss: 0.0757\n",
      "Epoch 148/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9580 - loss: 0.1179 - val_accuracy: 0.9637 - val_loss: 0.0917\n",
      "Epoch 149/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9541 - loss: 0.1363 - val_accuracy: 0.9787 - val_loss: 0.0775\n",
      "Epoch 150/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9584 - loss: 0.1171 - val_accuracy: 0.9758 - val_loss: 0.0763\n",
      "Epoch 151/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9596 - loss: 0.1193 - val_accuracy: 0.9755 - val_loss: 0.0771\n",
      "Epoch 152/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9603 - loss: 0.1158 - val_accuracy: 0.9726 - val_loss: 0.0819\n",
      "Epoch 153/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9576 - loss: 0.1216 - val_accuracy: 0.9787 - val_loss: 0.0754\n",
      "Epoch 154/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9555 - loss: 0.1272 - val_accuracy: 0.9766 - val_loss: 0.0769\n",
      "Epoch 155/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9596 - loss: 0.1212 - val_accuracy: 0.9789 - val_loss: 0.0750\n",
      "Epoch 156/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9565 - loss: 0.1258 - val_accuracy: 0.9695 - val_loss: 0.0922\n",
      "Epoch 157/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.1150 - val_accuracy: 0.9766 - val_loss: 0.0717\n",
      "Epoch 158/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9587 - loss: 0.1252 - val_accuracy: 0.9734 - val_loss: 0.0785\n",
      "Epoch 159/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9602 - loss: 0.1141 - val_accuracy: 0.9750 - val_loss: 0.0794\n",
      "Epoch 160/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9549 - loss: 0.1270 - val_accuracy: 0.9745 - val_loss: 0.0785\n",
      "Epoch 161/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9560 - loss: 0.1278 - val_accuracy: 0.9716 - val_loss: 0.0833\n",
      "Epoch 162/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9552 - loss: 0.1234 - val_accuracy: 0.9758 - val_loss: 0.0702\n",
      "Epoch 163/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9615 - loss: 0.1153 - val_accuracy: 0.9753 - val_loss: 0.0851\n",
      "Epoch 164/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9588 - loss: 0.1218 - val_accuracy: 0.9753 - val_loss: 0.0774\n",
      "Epoch 165/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9619 - loss: 0.1201 - val_accuracy: 0.9721 - val_loss: 0.0893\n",
      "Epoch 166/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9590 - loss: 0.1189 - val_accuracy: 0.9800 - val_loss: 0.0716\n",
      "Epoch 167/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9602 - loss: 0.1128 - val_accuracy: 0.9784 - val_loss: 0.0760\n",
      "Epoch 168/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9575 - loss: 0.1227 - val_accuracy: 0.9779 - val_loss: 0.0673\n",
      "Epoch 169/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9601 - loss: 0.1156 - val_accuracy: 0.9774 - val_loss: 0.0735\n",
      "Epoch 170/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9584 - loss: 0.1137 - val_accuracy: 0.9766 - val_loss: 0.0734\n",
      "Epoch 171/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9582 - loss: 0.1239 - val_accuracy: 0.9768 - val_loss: 0.0750\n",
      "Epoch 172/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9618 - loss: 0.1080 - val_accuracy: 0.9745 - val_loss: 0.0717\n",
      "Epoch 173/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9615 - loss: 0.1148 - val_accuracy: 0.9782 - val_loss: 0.0724\n",
      "Epoch 174/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9629 - loss: 0.1170 - val_accuracy: 0.9739 - val_loss: 0.0775\n",
      "Epoch 175/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9577 - loss: 0.1164 - val_accuracy: 0.9766 - val_loss: 0.0718\n",
      "Epoch 176/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9601 - loss: 0.1205 - val_accuracy: 0.9776 - val_loss: 0.0725\n",
      "Epoch 177/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9601 - loss: 0.1179 - val_accuracy: 0.9789 - val_loss: 0.0721\n",
      "Epoch 178/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9609 - loss: 0.1183 - val_accuracy: 0.9774 - val_loss: 0.0734\n",
      "Epoch 179/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9569 - loss: 0.1176 - val_accuracy: 0.9737 - val_loss: 0.0745\n",
      "Epoch 180/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9624 - loss: 0.1168 - val_accuracy: 0.9745 - val_loss: 0.0771\n",
      "Epoch 181/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9630 - loss: 0.1118 - val_accuracy: 0.9734 - val_loss: 0.0798\n",
      "Epoch 182/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9558 - loss: 0.1320 - val_accuracy: 0.9779 - val_loss: 0.0696\n",
      "Epoch 183/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9591 - loss: 0.1203 - val_accuracy: 0.9776 - val_loss: 0.0758\n",
      "Epoch 184/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9592 - loss: 0.1144 - val_accuracy: 0.9792 - val_loss: 0.0686\n",
      "Epoch 185/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9611 - loss: 0.1113 - val_accuracy: 0.9766 - val_loss: 0.0739\n",
      "Epoch 186/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9607 - loss: 0.1194 - val_accuracy: 0.9776 - val_loss: 0.0686\n",
      "Epoch 187/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9620 - loss: 0.1107 - val_accuracy: 0.9766 - val_loss: 0.0747\n",
      "Epoch 188/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9575 - loss: 0.1170 - val_accuracy: 0.9784 - val_loss: 0.0679\n",
      "Epoch 189/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9626 - loss: 0.1079 - val_accuracy: 0.9753 - val_loss: 0.0752\n",
      "Epoch 190/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9597 - loss: 0.1202 - val_accuracy: 0.9755 - val_loss: 0.0718\n",
      "Epoch 191/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9614 - loss: 0.1167 - val_accuracy: 0.9774 - val_loss: 0.0725\n",
      "Epoch 192/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9594 - loss: 0.1192 - val_accuracy: 0.9750 - val_loss: 0.0785\n",
      "Epoch 193/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9580 - loss: 0.1176 - val_accuracy: 0.9766 - val_loss: 0.0738\n",
      "Epoch 194/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9612 - loss: 0.1127 - val_accuracy: 0.9768 - val_loss: 0.0756\n",
      "Epoch 195/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9605 - loss: 0.1117 - val_accuracy: 0.9742 - val_loss: 0.0773\n",
      "Epoch 196/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9571 - loss: 0.1215 - val_accuracy: 0.9795 - val_loss: 0.0689\n",
      "Epoch 197/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9584 - loss: 0.1106 - val_accuracy: 0.9761 - val_loss: 0.0719\n",
      "Epoch 198/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9599 - loss: 0.1200 - val_accuracy: 0.9776 - val_loss: 0.0713\n",
      "Epoch 199/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9621 - loss: 0.1064 - val_accuracy: 0.9753 - val_loss: 0.0736\n",
      "Epoch 200/200\n",
      "\u001b[1m475/475\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9634 - loss: 0.1095 - val_accuracy: 0.9774 - val_loss: 0.0698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e0c3269670>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create and train a classifier on top of the mediapipe hand landmarker.\n",
    "#Its input will be the hand landmark and its output will be the label of the gesture done by the user.\n",
    "#It will be done using the keras framework\n",
    "\n",
    "#needs tensorflow, pandas, numpy and sklearn\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "data = pd.read_csv('D:\\progetto_video\\dataset\\dataset_tutto2.csv')\n",
    "\n",
    "#Otherwise, online download:\n",
    "'''\n",
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/leviens/Live-human-gesture-recognition-system/refs/heads/main/dataset/dataset_nuovo_nolabel.csv\"\n",
    "response = requests.get(url)\n",
    "\n",
    "with open(\"dataset_nuovo_nolabel.csv\", \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "print(\"File downloaded successfully.\")\n",
    "\n",
    "data = pd.read_csv(\"dataset_nuovo_nolabel.csv\")\n",
    "'''\n",
    "\n",
    "\n",
    "# The last colums is the label, the rest are the variables\n",
    "features = data.iloc[:, :-1].values\n",
    "labels = data.iloc[:, -1].values\n",
    "labels[:]-=1\n",
    "\n",
    "# One-hot encode the labels \n",
    "labels = tf.keras.utils.to_categorical(labels)\n",
    "#print(labels)\n",
    "\n",
    "\n",
    "# Normalize the features \n",
    "features = features.astype('float32')\n",
    "\n",
    "#Normalization: we apply a simple normalization as other types didn't work as well on this dataset\n",
    "features = features / np.max(features)\n",
    "\n",
    "features, X_test, labels, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(features.shape[1],)), # Input layer with size matching the number of features\n",
    "    Dropout(0.5), #dropout layer\n",
    "    Dense(128, activation='relu'), # Hidden layer\n",
    "    Dropout(0.5), #dropout layer\n",
    "    Dense(labels.shape[1], activation='softmax')  # Output layer with size matching the number of classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(features, labels, epochs=200, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Optionally, evaluate the model on a test dataset (not provided here)\n",
    "# test_loss, test_accuracy = model.evaluate(test_features, test_labels)\n",
    "# print(f'Test accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f64db56-373e-48c4-96ab-37276ac1fc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.9753 - loss: 0.0708\n",
      "Test accuracy: 0.9779\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d6b74f4-ff07-416f-a140-945b502d2d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\Marco\\AppData\\Local\\Temp\\ipykernel_13976\\293287653.py:4: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  model.save(os.path.join('D:\\progetto_video\\model','model_deeper_2.h5'))\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "#saves the model remotely\n",
    "\n",
    "import os\n",
    "model.save(os.path.join('D:\\progetto_video\\model','model_deeper_2.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d8aa5a8-3f75-480c-977f-124d9b32f4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m16,640\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │             \u001b[38;5;34m903\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">151,319</span> (591.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m151,319\u001b[0m (591.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,439</span> (197.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,439\u001b[0m (197.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,880</span> (394.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m100,880\u001b[0m (394.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c815f38-53e3-4794-9467-ac18beffe575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m149/149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       573\n",
      "           1       0.93      0.99      0.96       682\n",
      "           2       0.99      0.92      0.96       782\n",
      "           3       0.97      0.99      0.98       863\n",
      "           4       0.99      0.99      0.99       692\n",
      "           5       1.00      0.98      0.99       740\n",
      "           6       0.99      0.99      0.99       418\n",
      "\n",
      "    accuracy                           0.98      4750\n",
      "   macro avg       0.98      0.98      0.98      4750\n",
      "weighted avg       0.98      0.98      0.98      4750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#more in depth analysis of the results on the test set\n",
    "y_pred = model.predict(X_test)  \n",
    "\n",
    "#Convert one-hot encoded predictions to label indices\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "#Convert one-hot encoded y_test to label indices\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test_labels, y_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5eddbd8f-f524-4f0b-b98a-2b9460611997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2421\n",
      "           1       0.93      0.99      0.96      2829\n",
      "           2       0.99      0.93      0.96      3127\n",
      "           3       0.97      0.99      0.98      3302\n",
      "           4       0.99      0.99      0.99      2865\n",
      "           5       1.00      0.98      0.99      2837\n",
      "           6       0.99      1.00      0.99      1616\n",
      "\n",
      "    accuracy                           0.98     18997\n",
      "   macro avg       0.98      0.98      0.98     18997\n",
      "weighted avg       0.98      0.98      0.98     18997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#more in depth analysis of the results on the test set\n",
    "y_pred = model.predict(features)  \n",
    "\n",
    "#Convert one-hot encoded predictions to label indices\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "#Convert one-hot encoded y_test to label indices\n",
    "y_test_labels = np.argmax(labels, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test_labels, y_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b9d81d-d653-4d77-8f49-0175f9457502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
